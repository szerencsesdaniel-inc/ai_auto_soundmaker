"""
Batch feldolgoz√≥ modul
Feladata: T√∂bb forgat√≥k√∂nyv f√°jl automatikus feldolgoz√°sa.
"""

import os
import json
import csv
from pathlib import Path
from typing import List, Dict, Optional
from datetime import datetime

from script_parser import ScriptParser
from docx_parser import DocxParser
from voice_manager import VoiceManager
from tts_generator import TTSGenerator


class BatchProcessor:
    """
    Batch feldolgoz√≥ oszt√°ly.
    T√∂bb forgat√≥k√∂nyv f√°jlt dolgoz fel egyszerre.
    """
    
    def __init__(self, 
                 input_dir: str, 
                 output_base_dir: str = "batch_output",
                 api_key: str = None):
        """
        Inicializ√°lja a batch processort.
        
        Args:
            input_dir: Input mappa, ahol a forgat√≥k√∂nyv f√°jlok vannak
            output_base_dir: Alap output mappa
            api_key: ElevenLabs API kulcs
        """
        self.input_dir = Path(input_dir)
        self.output_base_dir = Path(output_base_dir)
        self.api_key = api_key
        
        # Output mappa l√©trehoz√°sa
        self.output_base_dir.mkdir(exist_ok=True)
        
        self.results = []
        self.total_files = 0
        self.processed_files = 0
        self.failed_files = []
    
    def find_script_files(self) -> List[Path]:
        """
        Megkeresi az √∂sszes t√°mogatott forgat√≥k√∂nyv f√°jlt az input mapp√°ban.
        
        Returns:
            List[Path]: F√°jlok list√°ja
        """
        supported_extensions = ['.txt', '.docx']
        files = []
        
        for ext in supported_extensions:
            files.extend(self.input_dir.glob(f'*{ext}'))
        
        # N√©v szerint rendez√©s
        files.sort()
        
        return files
    
    def create_output_directory(self, script_name: str) -> Path:
        """
        L√©trehoz egy output mapp√°t egy forgat√≥k√∂nyvh√∂z.
        
        Args:
            script_name: Forgat√≥k√∂nyv neve (f√°jln√©v kiterjeszt√©s n√©lk√ºl)
            
        Returns:
            Path: Output mappa el√©r√©si √∫tja
        """
        # Biztons√°gos mappan√©v (speci√°lis karakterek elt√°vol√≠t√°sa)
        safe_name = "".join(c for c in script_name if c.isalnum() or c in (' ', '-', '_')).strip()
        safe_name = safe_name.replace(' ', '_')
        
        output_dir = self.output_base_dir / safe_name
        output_dir.mkdir(exist_ok=True)
        
        return output_dir
    
    def process_single_file(self, 
                           file_path: Path, 
                           voice_manager: VoiceManager,
                           custom_mappings: Optional[Dict] = None) -> Dict:
        """
        Feldolgoz egy forgat√≥k√∂nyv f√°jlt.
        
        Args:
            file_path: Forgat√≥k√∂nyv f√°jl el√©r√©si √∫tja
            voice_manager: VoiceManager instance
            custom_mappings: Egyedi hang p√°ros√≠t√°sok (opcion√°lis)
            
        Returns:
            Dict: Feldolgoz√°s eredm√©nye
        """
        result = {
            'file': str(file_path),
            'name': file_path.stem,
            'success': False,
            'error': None,
            'dialogues_count': 0,
            'generated_count': 0,
            'output_dir': None
        }
        
        try:
            print(f"\n{'='*60}")
            print(f"üìÑ Feldolgoz√°s: {file_path.name}")
            print(f"{'='*60}\n")
            
            # Parser v√°laszt√°s a f√°jlt√≠pus alapj√°n
            if file_path.suffix.lower() == '.docx':
                parser = DocxParser(str(file_path))
            else:
                parser = ScriptParser(str(file_path))
            
            # Forgat√≥k√∂nyv feldolgoz√°sa
            parser_data = parser.parse()
            
            # Metaadatok ki√≠r√°sa
            print(f"üìå Forgat√≥k√∂nyv: {parser_data['metadata'].get('title', file_path.stem)}")
            print(f"üë• Szerepl≈ëk: {len(parser_data['characters'])}")
            print(f"üé¨ Jelenetek: {len(parser_data['scenes'])}")
            
            # Hangprofilok hozz√°rendel√©se
            if custom_mappings:
                for char, profile in custom_mappings.items():
                    if char in parser_data['characters']:
                        voice_manager.custom_mappings[char] = profile
            
            for character, description in parser_data['characters'].items():
                voice_manager.assign_voice_by_description(character, description)
            
            # Output mappa l√©trehoz√°sa
            output_dir = self.create_output_directory(file_path.stem)
            result['output_dir'] = str(output_dir)
            
            print(f"üìÅ Output mappa: {output_dir}")
            
            # P√°rbesz√©dek el≈ëk√©sz√≠t√©se
            dialogues = parser.get_all_dialogues()
            result['dialogues_count'] = len(dialogues)
            
            if not dialogues:
                raise Exception("Nincs p√°rbesz√©d a forgat√≥k√∂nyvben!")
            
            print(f"üí¨ P√°rbesz√©dek: {len(dialogues)}\n")
            
            # TTS gener√°l√°s
            tts_generator = TTSGenerator(self.api_key, str(output_dir))
            generated_results = tts_generator.generate_batch(
                dialogues, 
                voice_manager, 
                delay=0.5
            )
            
            # Sikeres gener√°l√°sok sz√°ma
            result['generated_count'] = sum(1 for r in generated_results if r['success'])
            
            # JSON √©s CSV ment√©s
            json_path = output_dir / "dialogues.json"
            csv_path = output_dir / "dialogues.csv"
            mappings_path = output_dir / "voice_mappings.json"
            
            with open(json_path, 'w', encoding='utf-8') as f:
                json.dump(generated_results, f, ensure_ascii=False, indent=2)
            
            self._save_csv(generated_results, csv_path)
            
            with open(mappings_path, 'w', encoding='utf-8') as f:
                json.dump(voice_manager.get_all_mappings(), f, ensure_ascii=False, indent=2)
            
            print(f"\n‚úÖ Sikeres feldolgoz√°s!")
            print(f"   Gener√°lt hangok: {result['generated_count']}/{result['dialogues_count']}")
            
            result['success'] = True
            
        except Exception as e:
            print(f"\n‚ùå Hiba: {e}")
            result['error'] = str(e)
            self.failed_files.append(str(file_path))
        
        return result
    
    def process_all(self, custom_mappings: Optional[Dict] = None) -> Dict:
        """
        Feldolgozza az √∂sszes forgat√≥k√∂nyv f√°jlt az input mapp√°ban.
        
        Args:
            custom_mappings: Egyedi hang p√°ros√≠t√°sok (opcion√°lis)
            
        Returns:
            Dict: Batch feldolgoz√°s √∂sszes√≠tett eredm√©nye
        """
        files = self.find_script_files()
        self.total_files = len(files)
        
        if self.total_files == 0:
            print(f"‚ùå Nincs forgat√≥k√∂nyv f√°jl a mapp√°ban: {self.input_dir}")
            print("   T√°mogatott form√°tumok: .txt, .docx")
            return {'success': False, 'error': 'No files found'}
        
        print(f"\nüé¨ BATCH FELDOLGOZ√ÅS IND√çT√ÅSA")
        print(f"{'='*60}")
        print(f"üìÇ Input mappa: {self.input_dir}")
        print(f"üìÅ Output mappa: {self.output_base_dir}")
        print(f"üìÑ Tal√°lt f√°jlok: {self.total_files}")
        print(f"{'='*60}\n")
        
        # Meger≈ës√≠t√©s k√©r√©se
        confirmation = input(f"‚ö†Ô∏è  {self.total_files} f√°jl feldolgoz√°sa kezd≈ëdik. Folytatod? (i/n): ").strip().lower()
        
        if confirmation != 'i':
            print("‚ùå Megszak√≠tva.")
            return {'success': False, 'cancelled': True}
        
        # Voice manager l√©trehoz√°sa
        voice_manager = VoiceManager(custom_mappings)
        
        # F√°jlok feldolgoz√°sa
        for i, file_path in enumerate(files, 1):
            print(f"\n[{i}/{self.total_files}] ", end="")
            
            result = self.process_single_file(file_path, voice_manager, custom_mappings)
            self.results.append(result)
            
            if result['success']:
                self.processed_files += 1
            
            # Voice manager tiszt√≠t√°sa a k√∂vetkez≈ë f√°jlhoz
            voice_manager.character_voice_map.clear()
        
        # √ñsszes√≠t≈ë jelent√©s ment√©se
        self._save_summary()
        
        return {
            'success': True,
            'total_files': self.total_files,
            'processed': self.processed_files,
            'failed': len(self.failed_files),
            'results': self.results
        }
    
    def _save_csv(self, data: list, output_path: Path):
        """Menti a p√°rbesz√©deket CSV form√°tumban."""
        if not data:
            return
        
        fieldnames = ['scene', 'slide_number', 'character', 'text', 'voice_id', 'file_name', 'success']
        
        with open(output_path, 'w', encoding='utf-8', newline='') as f:
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()
            
            for row in data:
                csv_row = {key: row.get(key, '') for key in fieldnames}
                writer.writerow(csv_row)
    
    def _save_summary(self):
        """Mentse az √∂sszes√≠tett jelent√©st."""
        summary_path = self.output_base_dir / "batch_summary.json"
        
        summary = {
            'timestamp': datetime.now().isoformat(),
            'input_directory': str(self.input_dir),
            'output_directory': str(self.output_base_dir),
            'total_files': self.total_files,
            'processed_files': self.processed_files,
            'failed_files': self.failed_files,
            'results': self.results
        }
        
        with open(summary_path, 'w', encoding='utf-8') as f:
            json.dump(summary, f, ensure_ascii=False, indent=2)
        
        print(f"\nüìä √ñsszes√≠t≈ë jelent√©s mentve: {summary_path}")
